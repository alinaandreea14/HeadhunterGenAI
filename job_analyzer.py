# ==============================================================================
# UI - APLICAÈšIA STREAMLIT
# ==============================================================================

import streamlit as st
import pandas as pd
from src.services.scraper import scrape_clean_job_text
from src.services.llm_service import analyze_job_with_ai

# Sidebar Informativ (FÄƒrÄƒ input de date sensibile)
with st.sidebar:
    st.header("ğŸ•µï¸ GenAI Headhunter")
    st.success("âœ… API Key Ã®ncÄƒrcat securizat")
    st.markdown("---")
    st.write("Acest tool demonstreazÄƒ:")
    st.write("â€¢ Web Scraping (BS4)")
    st.write("â€¢ Secure Env Variables")
    st.write("â€¢ Structured Data (Pydantic)")

st.title("ğŸ•µï¸ GenAI Headhunter Assistant")
st.markdown("TransformÄƒ orice Job Description Ã®ntr-o analizÄƒ structuratÄƒ folosind AI.")

# Tab-uri
tab1, tab2 = st.tabs(["ğŸš€ AnalizÄƒ Job", "ğŸ“Š Market Scan (Batch)"])

# --- TAB 1: ANALIZA UNUI SINGUR LINK ---
with tab1:
    st.subheader("AnalizeazÄƒ un Job URL")
    url_input = st.text_input("Introdu URL-ul:", placeholder="https://...")
    
    if st.button("AnalizeazÄƒ Job", key="btn_single"):
        if not url_input:
            st.warning("Te rugÄƒm introdu un URL.")
        else:
            with st.spinner("ğŸ•·ï¸ Scraping & ğŸ¤– AI Analysis..."):
                raw_text = scrape_clean_job_text(url_input)
            
            if "Error" in raw_text:
                st.error(raw_text)
            else:
                try:
                    data = analyze_job_with_ai(raw_text)
                    
                    # -- DISPLAY --
                    st.divider()
                    col_h1, col_h2 = st.columns([3, 1])
                    with col_h1:
                        st.markdown(f"### {data.role_title}")
                        st.caption(f"Companie: **{data.company_name}** | Nivel: **{data.seniority}**")
                        st.caption(f"Salariu: **{data.salary_range.min} - {data.salary_range.max} {data.salary_range.currency} {data.salary_range.frequency}**")
                        st.caption(f"LocaÈ›ie: **{data.job_location.city}, {data.job_location.country}**")
                    with col_h2:
                        color = "normal" if data.match_score > 70 else "inverse"
                        st.metric("Quality Score", f"{data.match_score}/100", delta_color=color)

                    # Detalii
                    c1, c2, c3 = st.columns(3)
                    c1.info(f"**Remote:** {'Da' if data.job_location.is_remote else 'Nu'}")
                    c2.success(f"**Tehnologii:** {len(data.tech_stack)}")
                    c3.error(f"**Red Flags:** {len(data.red_flags)}")

                    st.markdown(f"**ğŸ“ Rezumat:** {data.summary}")
                    st.markdown("#### ğŸ› ï¸ Tech Stack")
                    st.write(", ".join([f"`{tech}`" for tech in data.tech_stack]))

                    if data.red_flags:
                        st.markdown("#### ğŸš© Avertismente")
                        for flag in data.red_flags:
                            st.warning(f"âš ï¸ {flag}")

                except Exception as e:
                    st.error(f"Eroare AI: {str(e)}")

# --- TAB 2: BATCH PROCESSING ---
with tab2:
    st.subheader("ğŸ“Š ComparÄƒ mai multe joburi")
    urls_text = st.text_area("Paste URL-uri (unul pe linie):", height=150)
    
    if st.button("ScaneazÄƒ PiaÈ›a", key="btn_batch"):
        urls = [u.strip() for u in urls_text.split('\n') if u.strip()]
        
        if not urls:
            st.warning("Nu ai introdus link-uri.")
        else:
            results = []
            progress_bar = st.progress(0)
            status_text = st.empty()
            
            for i, link in enumerate(urls):
                status_text.text(f"Analizez {i+1}/{len(urls)}...")
                text = scrape_clean_job_text(link)
                
                if "Error" not in text:
                    try:
                        res = analyze_job_with_ai(text)
                        results.append({
                            "Role": res.role_title,
                            "Company": res.company_name,
                            "Seniority": res.seniority,
                            "Tech": res.tech_stack,
                            "Score": res.match_score
                        })
                    except:
                        pass # ContinuÄƒm chiar dacÄƒ unul crapÄƒ
                
                progress_bar.progress((i + 1) / len(urls))
            
            status_text.text("Gata!")
            
            if results:
                df = pd.DataFrame(results)
                st.dataframe(df)
                
                # Grafic simplu
                st.bar_chart(df['Seniority'].value_counts())